{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0dff808d-6852-4230-80d9-ab09c5320843",
   "metadata": {},
   "source": [
    "<H1>Project 7</H1>\n",
    "Load RSS content and then extract content from each link. Do this in multiple threads<br/>\n",
    "<H3>Requirements</H3>\n",
    "Load an RSS xml file (Format: https://www.w3schools.com/xml/xml_rss.asp)<br/>\n",
    "Loop through each link<br/>\n",
    "Extract content from each link and write to “output.txt”<br/>\n",
    "Execute reading from multiple links in parallel<br/>\n",
    "<H3>Error Handling</H3>\n",
    "Take care of case where no RSS xml file is available<br/>\n",
    "Take care of case where xml file is empty<br/>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9024a73e-b630-4b99-9fdf-545cb0ec606f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#RSS files\n",
    "\n",
    "#https://feeds.washingtonpost.com/rss/business/technology\n",
    "#https://news.yahoo.com/rss/science\n",
    "#https://feeds.feedburner.com/TechCrunch/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a44cbf3b-c0aa-4298-a8cf-4a9fea967c60",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/gb/x5kpsw713pn9_4tcsmkqgykr0000gn/T/ipykernel_62479/1846711081.py:15: XMLParsedAsHTMLWarning: It looks like you're parsing an XML document using an HTML parser. If this really is an HTML document (maybe it's XHTML?), you can ignore or filter this warning. If it's XML, you should know that using an XML parser will be more reliable. To parse this document as XML, make sure you have the lxml package installed, and pass the keyword argument `features=\"xml\"` into the BeautifulSoup constructor.\n",
      "  soup = bs4.BeautifulSoup(response.text,\"lxml\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "futures : {<Future at 0x169e2eba0 state=running>: 'https://www.yahoo.com/news/3-dozen-high-rise-buildings-173141377.html', <Future at 0x17a121370 state=running>: 'https://www.yahoo.com/news/two-stars-may-orbiting-other-160052730.html', <Future at 0x173f048f0 state=running>: 'https://www.yahoo.com/news/water-destruction-deadly-heat-associated-120220230.html', <Future at 0x179ae43b0 state=running>: 'https://www.yahoo.com/news/meet-endurance-pioneering-nasa-moon-110000420.html', <Future at 0x179ab2ab0 state=running>: 'https://www.yahoo.com/news/attackers-cannibalized-victims-early-bronze-231343442.html'}\n",
      "\n",
      "as_completed(futures) : <generator object as_completed at 0x167613940>\n",
      "\n",
      "future : <Future at 0x17a121370 state=finished returned str>\n",
      "\n",
      "futures[future] : https://www.yahoo.com/news/two-stars-may-orbiting-other-160052730.html\n",
      "Writing content from https://www.yahoo.com/news/two-stars-may-orbiting-other-160052730.html to file.\n",
      "\n",
      "future : <Future at 0x169e2eba0 state=finished returned str>\n",
      "\n",
      "futures[future] : https://www.yahoo.com/news/3-dozen-high-rise-buildings-173141377.html\n",
      "Writing content from https://www.yahoo.com/news/3-dozen-high-rise-buildings-173141377.html to file.\n",
      "\n",
      "future : <Future at 0x179ab2ab0 state=finished returned str>\n",
      "\n",
      "futures[future] : https://www.yahoo.com/news/attackers-cannibalized-victims-early-bronze-231343442.html\n",
      "Writing content from https://www.yahoo.com/news/attackers-cannibalized-victims-early-bronze-231343442.html to file.\n",
      "\n",
      "future : <Future at 0x179ae43b0 state=finished returned str>\n",
      "\n",
      "futures[future] : https://www.yahoo.com/news/meet-endurance-pioneering-nasa-moon-110000420.html\n",
      "Writing content from https://www.yahoo.com/news/meet-endurance-pioneering-nasa-moon-110000420.html to file.\n",
      "\n",
      "future : <Future at 0x173f048f0 state=finished returned str>\n",
      "\n",
      "futures[future] : https://www.yahoo.com/news/water-destruction-deadly-heat-associated-120220230.html\n",
      "Writing content from https://www.yahoo.com/news/water-destruction-deadly-heat-associated-120220230.html to file.\n",
      "completed processing!\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import bs4\n",
    "import xml.etree.ElementTree as ET\n",
    "import os\n",
    "from concurrent.futures import ThreadPoolExecutor,as_completed\n",
    "\n",
    "RSS_URL = \"https://news.yahoo.com/rss/science\"\n",
    "MAX_THREADS = 5\n",
    "OUTPUT_FILE = \"output.txt\"\n",
    "\n",
    "def fetch_rss_feed_content(url):\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()\n",
    "        soup = bs4.BeautifulSoup(response.text,\"lxml\")\n",
    "        \n",
    "        return response.text\n",
    "    except requests.RequestException as e:\n",
    "        print(f\"Error fetching RSS feed: {e}\")\n",
    "        return None\n",
    "\n",
    "# Function to fetch content from a link\n",
    "def fetch_content_from_link(link):\n",
    "    try:\n",
    "        response = requests.get(link)\n",
    "        response.raise_for_status()\n",
    "        soup = bs4.BeautifulSoup(response.text, 'html.parser')\n",
    "        \n",
    "        content = soup.get_text()\n",
    "        return content.strip()  # Strip to avoid extra whitespaces\n",
    "    except requests.RequestException as e:\n",
    "        print(f\"Error fetching content from {link}: {e}\")\n",
    "        return None\n",
    "        \n",
    "def parse_rss_feed_contents(rss_feed_content):\n",
    "    try:\n",
    "        tree = ET.fromstring(rss_feed_content)\n",
    "    \n",
    "        links = []\n",
    "        for item_list in tree.findall('.//item'):\n",
    "            for link in item_list.iter('link'):\n",
    "                links.append(link.text)\n",
    "        return links\n",
    "    except Exception as e:\n",
    "        print(f\"Error parsing RSS feed: {e}\")\n",
    "        return []\n",
    "        \n",
    "def write_to_output_file(output_file, content, link):\n",
    "    try:\n",
    "        with open(output_file, \"a\", encoding=\"utf-8\") as f:\n",
    "            f.write(f\"\\nThe contents from link [{link}] : \\n\")\n",
    "            f.write(content+\"\\n\\n\")\n",
    "    except Exception as e:\n",
    "        print(\"Error while writing to file\", e.args('msg'))\n",
    "        return None\n",
    "\n",
    "def process_rss_feed():\n",
    "    rss_content = fetch_rss_feed_content(RSS_URL)\n",
    "    if not rss_content:\n",
    "        print(\"Failed to fetch RSS feed.\")\n",
    "        return\n",
    "\n",
    "    links = parse_rss_feed_contents(rss_content)\n",
    "    if not links:\n",
    "        print(\"No links found in the RSS feed.\")\n",
    "        return\n",
    "\n",
    "    # Create a ThreadPoolExecutor to fetch content in parallel\n",
    "    with ThreadPoolExecutor(max_workers=MAX_THREADS) as executor:\n",
    "        futures = {executor.submit(fetch_content_from_link, link): link for link in links}\n",
    "        print(f\"\\nfutures : {futures}\")\n",
    "        print(f\"\\nas_completed(futures) : {as_completed(futures)}\")\n",
    "        for future in as_completed(futures):\n",
    "            print(f\"\\nfuture : {future}\")\n",
    "            print(f\"\\nfutures[future] : {futures[future]}\")\n",
    "\n",
    "            link = futures[future]\n",
    "            try:\n",
    "                content = future.result()\n",
    "                if content:\n",
    "                    print(f\"Writing content from {link} to file.\")\n",
    "                    write_to_output_file(OUTPUT_FILE, content, link)\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {link}: {e}\")\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    if os.path.exists(OUTPUT_FILE):\n",
    "        os.remove(OUTPUT_FILE)  # Clear output file if it already exists\n",
    "\n",
    "    process_rss_feed()\n",
    "\n",
    "print(\"completed processing!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e0c937-a3c6-41c2-9d43-862b5611cdfa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
